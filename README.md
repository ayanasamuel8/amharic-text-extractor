# ğŸ“š Amharic NER Pipeline for EthioMart

This repository contains tools and scripts to preprocess Amharic Telegram text data, perform Named Entity Recognition (NER) using a fine-tuned transformer model, and extract vendor analytics for micro-lending evaluation.

---

## âœ¨ Features

- **âœ… Text Cleaning & Normalization**
  - Removes emojis, symbols, links, and redundant punctuation.
  - Normalizes Amharic-specific characters and spacing.

- **ğŸ”  Tokenization**
  - Uses `XLM-RoBERTa` tokenizer for multilingual support.
  - Token-level formatting for CoNLL-style entity tagging.

- **ğŸ·ï¸ NER Annotation Support**
  - Manual annotation via CoNLL format.
  - Supports entity labels:
    - `B-PRICE`, `I-PRICE`
    - `B-PRODUCT`, `I-PRODUCT`
    - `B-LOC`, `I-LOC`
    - `O` for non-entity tokens

- **ğŸ§  Model Fine-tuning**
  - Fine-tunes `xlm-roberta-base` on Amharic NER data.
  - Built using Hugging Face Transformers.

- **ğŸ“Š Vendor Analytics & Scorecard**
  - Extracts product/price entities from vendor posts.
  - Computes posting frequency, engagement metrics, and Lending Score.

---

## ğŸ—‚ï¸ Project Structure
``` yaml
/
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ preprocess.py # Cleaning and tokenization
â”‚ â”œâ”€â”€ ner_utils.py # Entity extraction utilities
â”‚ â”œâ”€â”€ vendor_metrics.py # Scorecard computation
â”‚ â””â”€â”€ telegram_scraper.py # Telegram data scraping
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Raw Telegram data
â”‚ â”œâ”€â”€ processed/ # Cleaned + enriched data
â”‚ â””â”€â”€ labeled_conll/ # CoNLL annotated data
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ trained_models/ # Fine-tuned XLM-RoBERTa model
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_preprocessing.ipynb
â”‚ â”œâ”€â”€ 03_fine_tuning.ipynb
â”‚ â”œâ”€â”€ 05_lime_and_shap.ipynb
â”‚ â””â”€â”€ 08_scorecard_analysis.ipynb
â”‚
â”œâ”€â”€ interpretability/
â”‚ â””â”€â”€ difficult_cases.md # Model errors & discussion
â”‚
â”œâ”€â”€ outputs/
â”‚ â””â”€â”€ enriched_data.csv # Product/price enriched records
â”‚
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_preprocess.py
â”‚ â””â”€â”€ test_dummy.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### ğŸ“¦ Installation

```bash
git clone https://github.com/yourname/ethiomart-ner.git
cd ethiomart-ner
pip install -r requirements.txt
```
## ğŸ§¹ Step 1: Preprocessing
```python
from scripts.preprocess import preprocess_dataframe
import pandas as pd

df = pd.read_csv("data/raw/telegram_data.csv")
cleaned_df = preprocess_dataframe(df, text_col="Message")
cleaned_df.to_csv("data/processed/cleaned_messages.csv", index=False)
```
## âœï¸ Step 2: Manual NER Labeling
Use a subset of cleaned messages.

Annotate each token in CoNLL format:

```css
áˆµáˆáŠ­  B-PRODUCT
á‰     O
2000 B-PRICE
á‰¥áˆ­   I-PRICE
```
Save labeled data in data/labeled_conll/ with blank lines between sentences.

## ğŸ§  Step 3: Model Training
Run training via notebook:

```bash
notebooks/03_fine_tuning.ipynb
```
### Model output saved to:

```bash
models/trained_models/
```
## ğŸ” Step 4: Entity Extraction
Use the fine-tuned model to extract product and price entities:

```python
from scripts.ner_utils import load_ner_pipeline, enrich_dataframe_with_entities
import pandas as pd

df = pd.read_csv("data/processed/cleaned_messages.csv")
ner_pipe = load_ner_pipeline("models/trained_models/")
df_enriched = enrich_dataframe_with_entities(df, text_col="cleaned_text", ner_pipeline=ner_pipe)
df_enriched.to_csv("outputs/enriched_data.csv", index=False)
```
## ğŸ“Š Step 5: Vendor Scorecard
Generate vendor-level analytics and a Lending Score:

```python
from scripts.vendor_metrics import prepare_prices, compute_vendor_metrics

df = pd.read_csv("outputs/enriched_data.csv")
df = prepare_prices(df)
scorecard_df = compute_vendor_metrics(df)
scorecard_df.to_csv("outputs/vendor_scorecard.csv", index=False)
```
## âœ… Tests
```bash
pytest
```
## Covers:

### Preprocessing and normalization

### Entity extraction logic

# ğŸ“Œ Contributing
We welcome contributions that:

- Improve preprocessing for Amharic

- Add more entity classes

- Enhance analytics (e.g., customer sentiment, time series trends)

1. Fork the repo

2. Create your feature branch (git checkout -b feature/amharic-cleaner)

3. Commit your changes

4. Open a pull request

# ğŸ§­ Future Roadmap
- âœ… Live Telegram feed scoring

- ğŸš§ Expand labeled dataset size

- ğŸš§ Add dashboard for scorecard insights

- ğŸš§ Support other Ethiopian languages (e.g., Afaan Oromoo)

# ğŸ“œ License

MIT License â€“ open-source and community-friendly!

EthioMart NLP | Powered by XLM-R and Open Source Intelligence ğŸ‡ªğŸ‡¹